{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar-10_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN/kA+5A5dlzhXrmtAEe61j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IfyAngelo/CIFAR-10-Image-Classifier/blob/main/cifar_10_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9j7udgnPDkb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a8030fc-2bd2-4077-8a8d-2ad1b8cd0661"
      },
      "source": [
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import BatchNormalization\n",
        " \n",
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "\t# load dataset\n",
        "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        " \n",
        "\t# one hot encode target values\n",
        "\ttrainY = to_categorical(trainY)\n",
        "\ttestY = to_categorical(testY)\n",
        "\treturn trainX, trainY, testX, testY\n",
        " \n",
        "# scale pixels\n",
        "def prep_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        " \n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm\n",
        " \n",
        "# define cnn model\n",
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.3))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.4))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\tmodel.add(Dense(10, activation='softmax'))\n",
        " \n",
        "\t# compile model\n",
        "\topt = SGD(learning_rate=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        " \n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# load dataset\n",
        "\ttrainX, trainY, testX, testY = load_dataset()\n",
        " \n",
        "\t# prepare pixel data\n",
        "\ttrainX, testX = prep_pixels(trainX, testX)\n",
        " \n",
        "\t# define model\n",
        "\tmodel = define_model()\n",
        " \n",
        "\t# create data generator\n",
        "\tdatagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        " \n",
        "\t# prepare iterator\n",
        "\tit_train = datagen.flow(trainX, trainY, batch_size=64)\n",
        " \n",
        "\t# fit model\n",
        "\tsteps = int(trainX.shape[0] / 64)\n",
        "\thistory = model.fit(it_train, steps_per_epoch=steps, epochs=200, validation_data=(testX, testY), verbose=2)\n",
        " \n",
        "\t# evaluate model\n",
        "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
        "\tprint('Validation Accuracy > %.3f' % (acc * 100.0))\n",
        " \n",
        " \n",
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n",
            "170508288/170498071 [==============================] - 11s 0us/step\n",
            "Epoch 1/200\n",
            "781/781 - 63s - loss: 2.1583 - accuracy: 0.2855 - val_loss: 1.5445 - val_accuracy: 0.4361\n",
            "Epoch 2/200\n",
            "781/781 - 33s - loss: 1.6472 - accuracy: 0.3949 - val_loss: 1.3877 - val_accuracy: 0.4884\n",
            "Epoch 3/200\n",
            "781/781 - 33s - loss: 1.5062 - accuracy: 0.4492 - val_loss: 1.3956 - val_accuracy: 0.4784\n",
            "Epoch 4/200\n",
            "781/781 - 33s - loss: 1.4176 - accuracy: 0.4831 - val_loss: 1.4855 - val_accuracy: 0.4455\n",
            "Epoch 5/200\n",
            "781/781 - 33s - loss: 1.3538 - accuracy: 0.5072 - val_loss: 1.3682 - val_accuracy: 0.4939\n",
            "Epoch 6/200\n",
            "781/781 - 33s - loss: 1.2947 - accuracy: 0.5312 - val_loss: 1.1843 - val_accuracy: 0.5651\n",
            "Epoch 7/200\n",
            "781/781 - 33s - loss: 1.2384 - accuracy: 0.5543 - val_loss: 1.3245 - val_accuracy: 0.5101\n",
            "Epoch 8/200\n",
            "781/781 - 33s - loss: 1.2036 - accuracy: 0.5674 - val_loss: 1.1461 - val_accuracy: 0.5783\n",
            "Epoch 9/200\n",
            "781/781 - 33s - loss: 1.1669 - accuracy: 0.5801 - val_loss: 1.1185 - val_accuracy: 0.5953\n",
            "Epoch 10/200\n",
            "781/781 - 33s - loss: 1.1306 - accuracy: 0.5935 - val_loss: 1.2821 - val_accuracy: 0.5484\n",
            "Epoch 11/200\n",
            "781/781 - 33s - loss: 1.1059 - accuracy: 0.6047 - val_loss: 1.1608 - val_accuracy: 0.5864\n",
            "Epoch 12/200\n",
            "781/781 - 33s - loss: 1.0812 - accuracy: 0.6125 - val_loss: 1.0332 - val_accuracy: 0.6288\n",
            "Epoch 13/200\n",
            "781/781 - 33s - loss: 1.0613 - accuracy: 0.6234 - val_loss: 1.0264 - val_accuracy: 0.6286\n",
            "Epoch 14/200\n",
            "781/781 - 33s - loss: 1.0389 - accuracy: 0.6312 - val_loss: 0.9901 - val_accuracy: 0.6435\n",
            "Epoch 15/200\n",
            "781/781 - 33s - loss: 1.0198 - accuracy: 0.6389 - val_loss: 1.0048 - val_accuracy: 0.6435\n",
            "Epoch 16/200\n",
            "781/781 - 33s - loss: 1.0005 - accuracy: 0.6432 - val_loss: 0.9252 - val_accuracy: 0.6687\n",
            "Epoch 17/200\n",
            "781/781 - 34s - loss: 0.9830 - accuracy: 0.6518 - val_loss: 0.9571 - val_accuracy: 0.6557\n",
            "Epoch 18/200\n",
            "781/781 - 33s - loss: 0.9713 - accuracy: 0.6559 - val_loss: 0.8828 - val_accuracy: 0.6793\n",
            "Epoch 19/200\n",
            "781/781 - 33s - loss: 0.9488 - accuracy: 0.6646 - val_loss: 0.9425 - val_accuracy: 0.6645\n",
            "Epoch 20/200\n",
            "781/781 - 33s - loss: 0.9373 - accuracy: 0.6707 - val_loss: 0.9262 - val_accuracy: 0.6680\n",
            "Epoch 21/200\n",
            "781/781 - 33s - loss: 0.9274 - accuracy: 0.6721 - val_loss: 0.8603 - val_accuracy: 0.6919\n",
            "Epoch 22/200\n",
            "781/781 - 34s - loss: 0.9081 - accuracy: 0.6775 - val_loss: 0.8771 - val_accuracy: 0.6866\n",
            "Epoch 23/200\n",
            "781/781 - 33s - loss: 0.8971 - accuracy: 0.6832 - val_loss: 0.8878 - val_accuracy: 0.6834\n",
            "Epoch 24/200\n",
            "781/781 - 33s - loss: 0.8848 - accuracy: 0.6879 - val_loss: 0.8903 - val_accuracy: 0.6814\n",
            "Epoch 25/200\n",
            "781/781 - 33s - loss: 0.8833 - accuracy: 0.6911 - val_loss: 0.8251 - val_accuracy: 0.7051\n",
            "Epoch 26/200\n",
            "781/781 - 33s - loss: 0.8706 - accuracy: 0.6943 - val_loss: 0.8224 - val_accuracy: 0.7043\n",
            "Epoch 27/200\n",
            "781/781 - 32s - loss: 0.8570 - accuracy: 0.6981 - val_loss: 0.8386 - val_accuracy: 0.6997\n",
            "Epoch 28/200\n",
            "781/781 - 32s - loss: 0.8437 - accuracy: 0.7007 - val_loss: 0.8008 - val_accuracy: 0.7138\n",
            "Epoch 29/200\n",
            "781/781 - 32s - loss: 0.8434 - accuracy: 0.7049 - val_loss: 0.8722 - val_accuracy: 0.6920\n",
            "Epoch 30/200\n",
            "781/781 - 32s - loss: 0.8282 - accuracy: 0.7089 - val_loss: 0.8281 - val_accuracy: 0.7045\n",
            "Epoch 31/200\n",
            "781/781 - 32s - loss: 0.8165 - accuracy: 0.7155 - val_loss: 0.7522 - val_accuracy: 0.7368\n",
            "Epoch 32/200\n",
            "781/781 - 33s - loss: 0.8142 - accuracy: 0.7129 - val_loss: 0.6983 - val_accuracy: 0.7523\n",
            "Epoch 33/200\n",
            "781/781 - 32s - loss: 0.8056 - accuracy: 0.7178 - val_loss: 0.7989 - val_accuracy: 0.7166\n",
            "Epoch 34/200\n",
            "781/781 - 32s - loss: 0.8037 - accuracy: 0.7198 - val_loss: 0.7376 - val_accuracy: 0.7383\n",
            "Epoch 35/200\n",
            "781/781 - 33s - loss: 0.7907 - accuracy: 0.7243 - val_loss: 0.7751 - val_accuracy: 0.7260\n",
            "Epoch 36/200\n",
            "781/781 - 32s - loss: 0.7839 - accuracy: 0.7252 - val_loss: 0.7189 - val_accuracy: 0.7451\n",
            "Epoch 37/200\n",
            "781/781 - 32s - loss: 0.7797 - accuracy: 0.7267 - val_loss: 0.7835 - val_accuracy: 0.7225\n",
            "Epoch 38/200\n",
            "781/781 - 32s - loss: 0.7745 - accuracy: 0.7279 - val_loss: 0.8002 - val_accuracy: 0.7148\n",
            "Epoch 39/200\n",
            "781/781 - 33s - loss: 0.7606 - accuracy: 0.7361 - val_loss: 0.7303 - val_accuracy: 0.7432\n",
            "Epoch 40/200\n",
            "781/781 - 32s - loss: 0.7554 - accuracy: 0.7384 - val_loss: 0.7401 - val_accuracy: 0.7400\n",
            "Epoch 41/200\n",
            "781/781 - 33s - loss: 0.7552 - accuracy: 0.7346 - val_loss: 0.6867 - val_accuracy: 0.7592\n",
            "Epoch 42/200\n",
            "781/781 - 32s - loss: 0.7476 - accuracy: 0.7376 - val_loss: 0.7255 - val_accuracy: 0.7455\n",
            "Epoch 43/200\n",
            "781/781 - 32s - loss: 0.7450 - accuracy: 0.7407 - val_loss: 0.6882 - val_accuracy: 0.7588\n",
            "Epoch 44/200\n",
            "781/781 - 33s - loss: 0.7433 - accuracy: 0.7407 - val_loss: 0.7145 - val_accuracy: 0.7493\n",
            "Epoch 45/200\n",
            "781/781 - 32s - loss: 0.7316 - accuracy: 0.7450 - val_loss: 0.6606 - val_accuracy: 0.7659\n",
            "Epoch 46/200\n",
            "781/781 - 32s - loss: 0.7273 - accuracy: 0.7469 - val_loss: 0.6756 - val_accuracy: 0.7622\n",
            "Epoch 47/200\n",
            "781/781 - 32s - loss: 0.7183 - accuracy: 0.7495 - val_loss: 0.6896 - val_accuracy: 0.7569\n",
            "Epoch 48/200\n",
            "781/781 - 32s - loss: 0.7222 - accuracy: 0.7497 - val_loss: 0.6831 - val_accuracy: 0.7591\n",
            "Epoch 49/200\n",
            "781/781 - 32s - loss: 0.7120 - accuracy: 0.7534 - val_loss: 0.6494 - val_accuracy: 0.7737\n",
            "Epoch 50/200\n",
            "781/781 - 33s - loss: 0.7076 - accuracy: 0.7532 - val_loss: 0.7375 - val_accuracy: 0.7471\n",
            "Epoch 51/200\n",
            "781/781 - 33s - loss: 0.7040 - accuracy: 0.7549 - val_loss: 0.6390 - val_accuracy: 0.7756\n",
            "Epoch 52/200\n",
            "781/781 - 34s - loss: 0.6894 - accuracy: 0.7623 - val_loss: 0.6651 - val_accuracy: 0.7690\n",
            "Epoch 53/200\n",
            "781/781 - 33s - loss: 0.6923 - accuracy: 0.7613 - val_loss: 0.6123 - val_accuracy: 0.7880\n",
            "Epoch 54/200\n",
            "781/781 - 33s - loss: 0.6907 - accuracy: 0.7605 - val_loss: 0.6796 - val_accuracy: 0.7650\n",
            "Epoch 55/200\n",
            "781/781 - 33s - loss: 0.6884 - accuracy: 0.7625 - val_loss: 0.6065 - val_accuracy: 0.7894\n",
            "Epoch 56/200\n",
            "781/781 - 33s - loss: 0.6781 - accuracy: 0.7658 - val_loss: 0.6100 - val_accuracy: 0.7848\n",
            "Epoch 57/200\n",
            "781/781 - 33s - loss: 0.6721 - accuracy: 0.7667 - val_loss: 0.5811 - val_accuracy: 0.7974\n",
            "Epoch 58/200\n",
            "781/781 - 33s - loss: 0.6725 - accuracy: 0.7671 - val_loss: 0.6156 - val_accuracy: 0.7844\n",
            "Epoch 59/200\n",
            "781/781 - 34s - loss: 0.6657 - accuracy: 0.7683 - val_loss: 0.6421 - val_accuracy: 0.7725\n",
            "Epoch 60/200\n",
            "781/781 - 34s - loss: 0.6593 - accuracy: 0.7707 - val_loss: 0.6459 - val_accuracy: 0.7766\n",
            "Epoch 61/200\n",
            "781/781 - 34s - loss: 0.6568 - accuracy: 0.7723 - val_loss: 0.6643 - val_accuracy: 0.7680\n",
            "Epoch 62/200\n",
            "781/781 - 34s - loss: 0.6563 - accuracy: 0.7717 - val_loss: 0.6347 - val_accuracy: 0.7785\n",
            "Epoch 63/200\n",
            "781/781 - 34s - loss: 0.6502 - accuracy: 0.7745 - val_loss: 0.6157 - val_accuracy: 0.7868\n",
            "Epoch 64/200\n",
            "781/781 - 34s - loss: 0.6455 - accuracy: 0.7783 - val_loss: 0.6499 - val_accuracy: 0.7750\n",
            "Epoch 65/200\n",
            "781/781 - 34s - loss: 0.6429 - accuracy: 0.7775 - val_loss: 0.6116 - val_accuracy: 0.7893\n",
            "Epoch 66/200\n",
            "781/781 - 34s - loss: 0.6348 - accuracy: 0.7800 - val_loss: 0.5945 - val_accuracy: 0.7975\n",
            "Epoch 67/200\n",
            "781/781 - 34s - loss: 0.6369 - accuracy: 0.7802 - val_loss: 0.5931 - val_accuracy: 0.7956\n",
            "Epoch 68/200\n",
            "781/781 - 34s - loss: 0.6337 - accuracy: 0.7815 - val_loss: 0.6266 - val_accuracy: 0.7822\n",
            "Epoch 69/200\n",
            "781/781 - 34s - loss: 0.6269 - accuracy: 0.7857 - val_loss: 0.5904 - val_accuracy: 0.7958\n",
            "Epoch 70/200\n",
            "781/781 - 34s - loss: 0.6217 - accuracy: 0.7845 - val_loss: 0.5470 - val_accuracy: 0.8153\n",
            "Epoch 71/200\n",
            "781/781 - 34s - loss: 0.6168 - accuracy: 0.7873 - val_loss: 0.5284 - val_accuracy: 0.8194\n",
            "Epoch 72/200\n",
            "781/781 - 34s - loss: 0.6177 - accuracy: 0.7879 - val_loss: 0.5788 - val_accuracy: 0.8017\n",
            "Epoch 73/200\n",
            "781/781 - 34s - loss: 0.6142 - accuracy: 0.7888 - val_loss: 0.5807 - val_accuracy: 0.7997\n",
            "Epoch 74/200\n",
            "781/781 - 34s - loss: 0.6081 - accuracy: 0.7917 - val_loss: 0.5891 - val_accuracy: 0.7973\n",
            "Epoch 75/200\n",
            "781/781 - 34s - loss: 0.6128 - accuracy: 0.7910 - val_loss: 0.5888 - val_accuracy: 0.7977\n",
            "Epoch 76/200\n",
            "781/781 - 34s - loss: 0.6055 - accuracy: 0.7915 - val_loss: 0.6504 - val_accuracy: 0.7784\n",
            "Epoch 77/200\n",
            "781/781 - 34s - loss: 0.6044 - accuracy: 0.7926 - val_loss: 0.5577 - val_accuracy: 0.8119\n",
            "Epoch 78/200\n",
            "781/781 - 34s - loss: 0.5989 - accuracy: 0.7944 - val_loss: 0.5310 - val_accuracy: 0.8181\n",
            "Epoch 79/200\n",
            "781/781 - 34s - loss: 0.5972 - accuracy: 0.7951 - val_loss: 0.5559 - val_accuracy: 0.8111\n",
            "Epoch 80/200\n",
            "781/781 - 34s - loss: 0.5950 - accuracy: 0.7956 - val_loss: 0.5481 - val_accuracy: 0.8121\n",
            "Epoch 81/200\n",
            "781/781 - 33s - loss: 0.5908 - accuracy: 0.7969 - val_loss: 0.5096 - val_accuracy: 0.8257\n",
            "Epoch 82/200\n",
            "781/781 - 34s - loss: 0.5815 - accuracy: 0.8005 - val_loss: 0.5378 - val_accuracy: 0.8179\n",
            "Epoch 83/200\n",
            "781/781 - 33s - loss: 0.5841 - accuracy: 0.7984 - val_loss: 0.5416 - val_accuracy: 0.8173\n",
            "Epoch 84/200\n",
            "781/781 - 34s - loss: 0.5815 - accuracy: 0.8010 - val_loss: 0.5142 - val_accuracy: 0.8259\n",
            "Epoch 85/200\n",
            "781/781 - 35s - loss: 0.5813 - accuracy: 0.8011 - val_loss: 0.5330 - val_accuracy: 0.8194\n",
            "Epoch 86/200\n",
            "781/781 - 34s - loss: 0.5706 - accuracy: 0.8062 - val_loss: 0.4966 - val_accuracy: 0.8285\n",
            "Epoch 87/200\n",
            "781/781 - 34s - loss: 0.5739 - accuracy: 0.8031 - val_loss: 0.5148 - val_accuracy: 0.8237\n",
            "Epoch 88/200\n",
            "781/781 - 34s - loss: 0.5709 - accuracy: 0.8045 - val_loss: 0.4892 - val_accuracy: 0.8326\n",
            "Epoch 89/200\n",
            "781/781 - 32s - loss: 0.5684 - accuracy: 0.8043 - val_loss: 0.5153 - val_accuracy: 0.8233\n",
            "Epoch 90/200\n",
            "781/781 - 32s - loss: 0.5625 - accuracy: 0.8049 - val_loss: 0.5012 - val_accuracy: 0.8276\n",
            "Epoch 91/200\n",
            "781/781 - 33s - loss: 0.5586 - accuracy: 0.8080 - val_loss: 0.5182 - val_accuracy: 0.8242\n",
            "Epoch 92/200\n",
            "781/781 - 34s - loss: 0.5575 - accuracy: 0.8084 - val_loss: 0.5277 - val_accuracy: 0.8218\n",
            "Epoch 93/200\n",
            "781/781 - 32s - loss: 0.5580 - accuracy: 0.8080 - val_loss: 0.5177 - val_accuracy: 0.8255\n",
            "Epoch 94/200\n",
            "781/781 - 32s - loss: 0.5599 - accuracy: 0.8087 - val_loss: 0.5015 - val_accuracy: 0.8291\n",
            "Epoch 95/200\n",
            "781/781 - 32s - loss: 0.5521 - accuracy: 0.8098 - val_loss: 0.4888 - val_accuracy: 0.8349\n",
            "Epoch 96/200\n",
            "781/781 - 32s - loss: 0.5572 - accuracy: 0.8087 - val_loss: 0.4922 - val_accuracy: 0.8332\n",
            "Epoch 97/200\n",
            "781/781 - 33s - loss: 0.5432 - accuracy: 0.8133 - val_loss: 0.5192 - val_accuracy: 0.8236\n",
            "Epoch 98/200\n",
            "781/781 - 33s - loss: 0.5473 - accuracy: 0.8134 - val_loss: 0.4924 - val_accuracy: 0.8356\n",
            "Epoch 99/200\n",
            "781/781 - 34s - loss: 0.5439 - accuracy: 0.8134 - val_loss: 0.4918 - val_accuracy: 0.8353\n",
            "Epoch 100/200\n",
            "781/781 - 33s - loss: 0.5385 - accuracy: 0.8151 - val_loss: 0.4883 - val_accuracy: 0.8359\n",
            "Epoch 101/200\n",
            "781/781 - 33s - loss: 0.5365 - accuracy: 0.8149 - val_loss: 0.4960 - val_accuracy: 0.8324\n",
            "Epoch 102/200\n",
            "781/781 - 33s - loss: 0.5383 - accuracy: 0.8151 - val_loss: 0.4978 - val_accuracy: 0.8309\n",
            "Epoch 103/200\n",
            "781/781 - 33s - loss: 0.5333 - accuracy: 0.8165 - val_loss: 0.4894 - val_accuracy: 0.8313\n",
            "Epoch 104/200\n",
            "781/781 - 33s - loss: 0.5326 - accuracy: 0.8169 - val_loss: 0.4948 - val_accuracy: 0.8340\n",
            "Epoch 105/200\n",
            "781/781 - 33s - loss: 0.5312 - accuracy: 0.8184 - val_loss: 0.4741 - val_accuracy: 0.8397\n",
            "Epoch 106/200\n",
            "781/781 - 33s - loss: 0.5266 - accuracy: 0.8209 - val_loss: 0.4930 - val_accuracy: 0.8340\n",
            "Epoch 107/200\n",
            "781/781 - 33s - loss: 0.5277 - accuracy: 0.8187 - val_loss: 0.4901 - val_accuracy: 0.8343\n",
            "Epoch 108/200\n",
            "781/781 - 33s - loss: 0.5272 - accuracy: 0.8211 - val_loss: 0.4710 - val_accuracy: 0.8410\n",
            "Epoch 109/200\n",
            "781/781 - 33s - loss: 0.5236 - accuracy: 0.8201 - val_loss: 0.4745 - val_accuracy: 0.8419\n",
            "Epoch 110/200\n",
            "781/781 - 33s - loss: 0.5206 - accuracy: 0.8211 - val_loss: 0.4566 - val_accuracy: 0.8448\n",
            "Epoch 111/200\n",
            "781/781 - 33s - loss: 0.5136 - accuracy: 0.8236 - val_loss: 0.4992 - val_accuracy: 0.8352\n",
            "Epoch 112/200\n",
            "781/781 - 33s - loss: 0.5147 - accuracy: 0.8232 - val_loss: 0.4541 - val_accuracy: 0.8450\n",
            "Epoch 113/200\n",
            "781/781 - 33s - loss: 0.5133 - accuracy: 0.8258 - val_loss: 0.5021 - val_accuracy: 0.8293\n",
            "Epoch 114/200\n",
            "781/781 - 33s - loss: 0.5124 - accuracy: 0.8241 - val_loss: 0.4682 - val_accuracy: 0.8418\n",
            "Epoch 115/200\n",
            "781/781 - 33s - loss: 0.5112 - accuracy: 0.8250 - val_loss: 0.4562 - val_accuracy: 0.8452\n",
            "Epoch 116/200\n",
            "781/781 - 33s - loss: 0.5115 - accuracy: 0.8243 - val_loss: 0.4601 - val_accuracy: 0.8423\n",
            "Epoch 117/200\n",
            "781/781 - 33s - loss: 0.5059 - accuracy: 0.8266 - val_loss: 0.4515 - val_accuracy: 0.8458\n",
            "Epoch 118/200\n",
            "781/781 - 33s - loss: 0.5009 - accuracy: 0.8302 - val_loss: 0.4648 - val_accuracy: 0.8422\n",
            "Epoch 119/200\n",
            "781/781 - 33s - loss: 0.5073 - accuracy: 0.8262 - val_loss: 0.4604 - val_accuracy: 0.8444\n",
            "Epoch 120/200\n",
            "781/781 - 33s - loss: 0.4993 - accuracy: 0.8276 - val_loss: 0.4902 - val_accuracy: 0.8366\n",
            "Epoch 121/200\n",
            "781/781 - 33s - loss: 0.5014 - accuracy: 0.8278 - val_loss: 0.4363 - val_accuracy: 0.8533\n",
            "Epoch 122/200\n",
            "781/781 - 33s - loss: 0.4967 - accuracy: 0.8293 - val_loss: 0.4766 - val_accuracy: 0.8402\n",
            "Epoch 123/200\n",
            "781/781 - 33s - loss: 0.4938 - accuracy: 0.8314 - val_loss: 0.4666 - val_accuracy: 0.8438\n",
            "Epoch 124/200\n",
            "781/781 - 33s - loss: 0.4944 - accuracy: 0.8307 - val_loss: 0.4553 - val_accuracy: 0.8458\n",
            "Epoch 125/200\n",
            "781/781 - 33s - loss: 0.4916 - accuracy: 0.8315 - val_loss: 0.4797 - val_accuracy: 0.8392\n",
            "Epoch 126/200\n",
            "781/781 - 33s - loss: 0.4938 - accuracy: 0.8308 - val_loss: 0.4553 - val_accuracy: 0.8457\n",
            "Epoch 127/200\n",
            "781/781 - 33s - loss: 0.4870 - accuracy: 0.8328 - val_loss: 0.4490 - val_accuracy: 0.8495\n",
            "Epoch 128/200\n",
            "781/781 - 33s - loss: 0.4885 - accuracy: 0.8332 - val_loss: 0.4755 - val_accuracy: 0.8420\n",
            "Epoch 129/200\n",
            "781/781 - 33s - loss: 0.4880 - accuracy: 0.8321 - val_loss: 0.4623 - val_accuracy: 0.8449\n",
            "Epoch 130/200\n",
            "781/781 - 33s - loss: 0.4790 - accuracy: 0.8352 - val_loss: 0.4527 - val_accuracy: 0.8479\n",
            "Epoch 131/200\n",
            "781/781 - 33s - loss: 0.4819 - accuracy: 0.8345 - val_loss: 0.4479 - val_accuracy: 0.8472\n",
            "Epoch 132/200\n",
            "781/781 - 33s - loss: 0.4818 - accuracy: 0.8366 - val_loss: 0.4543 - val_accuracy: 0.8472\n",
            "Epoch 133/200\n",
            "781/781 - 33s - loss: 0.4732 - accuracy: 0.8389 - val_loss: 0.4876 - val_accuracy: 0.8364\n",
            "Epoch 134/200\n",
            "781/781 - 33s - loss: 0.4740 - accuracy: 0.8370 - val_loss: 0.4489 - val_accuracy: 0.8505\n",
            "Epoch 135/200\n",
            "781/781 - 33s - loss: 0.4760 - accuracy: 0.8381 - val_loss: 0.4411 - val_accuracy: 0.8519\n",
            "Epoch 136/200\n",
            "781/781 - 33s - loss: 0.4731 - accuracy: 0.8382 - val_loss: 0.4407 - val_accuracy: 0.8537\n",
            "Epoch 137/200\n",
            "781/781 - 33s - loss: 0.4754 - accuracy: 0.8370 - val_loss: 0.4521 - val_accuracy: 0.8497\n",
            "Epoch 138/200\n",
            "781/781 - 33s - loss: 0.4664 - accuracy: 0.8407 - val_loss: 0.4582 - val_accuracy: 0.8460\n",
            "Epoch 139/200\n",
            "781/781 - 33s - loss: 0.4704 - accuracy: 0.8407 - val_loss: 0.4388 - val_accuracy: 0.8521\n",
            "Epoch 140/200\n",
            "781/781 - 33s - loss: 0.4710 - accuracy: 0.8383 - val_loss: 0.4971 - val_accuracy: 0.8335\n",
            "Epoch 141/200\n",
            "781/781 - 33s - loss: 0.4692 - accuracy: 0.8387 - val_loss: 0.4153 - val_accuracy: 0.8618\n",
            "Epoch 142/200\n",
            "781/781 - 33s - loss: 0.4680 - accuracy: 0.8393 - val_loss: 0.4824 - val_accuracy: 0.8396\n",
            "Epoch 143/200\n",
            "781/781 - 33s - loss: 0.4687 - accuracy: 0.8408 - val_loss: 0.4434 - val_accuracy: 0.8527\n",
            "Epoch 144/200\n",
            "781/781 - 33s - loss: 0.4631 - accuracy: 0.8421 - val_loss: 0.4619 - val_accuracy: 0.8477\n",
            "Epoch 145/200\n",
            "781/781 - 33s - loss: 0.4651 - accuracy: 0.8421 - val_loss: 0.4398 - val_accuracy: 0.8531\n",
            "Epoch 146/200\n",
            "781/781 - 33s - loss: 0.4595 - accuracy: 0.8437 - val_loss: 0.4075 - val_accuracy: 0.8634\n",
            "Epoch 147/200\n",
            "781/781 - 33s - loss: 0.4550 - accuracy: 0.8437 - val_loss: 0.4377 - val_accuracy: 0.8534\n",
            "Epoch 148/200\n",
            "781/781 - 33s - loss: 0.4525 - accuracy: 0.8474 - val_loss: 0.4230 - val_accuracy: 0.8576\n",
            "Epoch 149/200\n",
            "781/781 - 33s - loss: 0.4603 - accuracy: 0.8425 - val_loss: 0.4267 - val_accuracy: 0.8563\n",
            "Epoch 150/200\n",
            "781/781 - 33s - loss: 0.4471 - accuracy: 0.8465 - val_loss: 0.4400 - val_accuracy: 0.8507\n",
            "Epoch 151/200\n",
            "781/781 - 33s - loss: 0.4548 - accuracy: 0.8435 - val_loss: 0.4221 - val_accuracy: 0.8602\n",
            "Epoch 152/200\n",
            "781/781 - 33s - loss: 0.4504 - accuracy: 0.8446 - val_loss: 0.4430 - val_accuracy: 0.8541\n",
            "Epoch 153/200\n",
            "781/781 - 33s - loss: 0.4567 - accuracy: 0.8447 - val_loss: 0.4746 - val_accuracy: 0.8426\n",
            "Epoch 154/200\n",
            "781/781 - 33s - loss: 0.4445 - accuracy: 0.8488 - val_loss: 0.4040 - val_accuracy: 0.8648\n",
            "Epoch 155/200\n",
            "781/781 - 33s - loss: 0.4447 - accuracy: 0.8489 - val_loss: 0.4189 - val_accuracy: 0.8603\n",
            "Epoch 156/200\n",
            "781/781 - 32s - loss: 0.4522 - accuracy: 0.8451 - val_loss: 0.4340 - val_accuracy: 0.8546\n",
            "Epoch 157/200\n",
            "781/781 - 32s - loss: 0.4458 - accuracy: 0.8481 - val_loss: 0.4293 - val_accuracy: 0.8575\n",
            "Epoch 158/200\n",
            "781/781 - 33s - loss: 0.4431 - accuracy: 0.8481 - val_loss: 0.4201 - val_accuracy: 0.8578\n",
            "Epoch 159/200\n",
            "781/781 - 33s - loss: 0.4405 - accuracy: 0.8499 - val_loss: 0.4329 - val_accuracy: 0.8551\n",
            "Epoch 160/200\n",
            "781/781 - 32s - loss: 0.4409 - accuracy: 0.8504 - val_loss: 0.4017 - val_accuracy: 0.8647\n",
            "Epoch 161/200\n",
            "781/781 - 33s - loss: 0.4371 - accuracy: 0.8494 - val_loss: 0.4359 - val_accuracy: 0.8564\n",
            "Epoch 162/200\n",
            "781/781 - 32s - loss: 0.4415 - accuracy: 0.8477 - val_loss: 0.4250 - val_accuracy: 0.8599\n",
            "Epoch 163/200\n",
            "781/781 - 32s - loss: 0.4361 - accuracy: 0.8509 - val_loss: 0.4024 - val_accuracy: 0.8631\n",
            "Epoch 164/200\n",
            "781/781 - 33s - loss: 0.4368 - accuracy: 0.8511 - val_loss: 0.4029 - val_accuracy: 0.8671\n",
            "Epoch 165/200\n",
            "781/781 - 33s - loss: 0.4348 - accuracy: 0.8509 - val_loss: 0.4163 - val_accuracy: 0.8620\n",
            "Epoch 166/200\n",
            "781/781 - 33s - loss: 0.4329 - accuracy: 0.8528 - val_loss: 0.4126 - val_accuracy: 0.8633\n",
            "Epoch 167/200\n",
            "781/781 - 33s - loss: 0.4321 - accuracy: 0.8533 - val_loss: 0.4047 - val_accuracy: 0.8633\n",
            "Epoch 168/200\n",
            "781/781 - 33s - loss: 0.4376 - accuracy: 0.8499 - val_loss: 0.4360 - val_accuracy: 0.8550\n",
            "Epoch 169/200\n",
            "781/781 - 33s - loss: 0.4279 - accuracy: 0.8549 - val_loss: 0.4347 - val_accuracy: 0.8543\n",
            "Epoch 170/200\n",
            "781/781 - 32s - loss: 0.4300 - accuracy: 0.8538 - val_loss: 0.3973 - val_accuracy: 0.8657\n",
            "Epoch 171/200\n",
            "781/781 - 33s - loss: 0.4371 - accuracy: 0.8495 - val_loss: 0.4218 - val_accuracy: 0.8619\n",
            "Epoch 172/200\n",
            "781/781 - 33s - loss: 0.4273 - accuracy: 0.8537 - val_loss: 0.3992 - val_accuracy: 0.8673\n",
            "Epoch 173/200\n",
            "781/781 - 33s - loss: 0.4234 - accuracy: 0.8559 - val_loss: 0.4591 - val_accuracy: 0.8489\n",
            "Epoch 174/200\n",
            "781/781 - 33s - loss: 0.4231 - accuracy: 0.8550 - val_loss: 0.3984 - val_accuracy: 0.8672\n",
            "Epoch 175/200\n",
            "781/781 - 33s - loss: 0.4265 - accuracy: 0.8545 - val_loss: 0.4221 - val_accuracy: 0.8594\n",
            "Epoch 176/200\n",
            "781/781 - 33s - loss: 0.4220 - accuracy: 0.8550 - val_loss: 0.3955 - val_accuracy: 0.8694\n",
            "Epoch 177/200\n",
            "781/781 - 32s - loss: 0.4211 - accuracy: 0.8557 - val_loss: 0.4898 - val_accuracy: 0.8408\n",
            "Epoch 178/200\n",
            "781/781 - 32s - loss: 0.4248 - accuracy: 0.8549 - val_loss: 0.4136 - val_accuracy: 0.8627\n",
            "Epoch 179/200\n",
            "781/781 - 33s - loss: 0.4200 - accuracy: 0.8559 - val_loss: 0.4259 - val_accuracy: 0.8626\n",
            "Epoch 180/200\n",
            "781/781 - 32s - loss: 0.4212 - accuracy: 0.8551 - val_loss: 0.4308 - val_accuracy: 0.8582\n",
            "Epoch 181/200\n",
            "781/781 - 33s - loss: 0.4163 - accuracy: 0.8585 - val_loss: 0.4096 - val_accuracy: 0.8637\n",
            "Epoch 182/200\n",
            "781/781 - 32s - loss: 0.4205 - accuracy: 0.8573 - val_loss: 0.3991 - val_accuracy: 0.8678\n",
            "Epoch 183/200\n",
            "781/781 - 32s - loss: 0.4115 - accuracy: 0.8579 - val_loss: 0.3862 - val_accuracy: 0.8724\n",
            "Epoch 184/200\n",
            "781/781 - 32s - loss: 0.4138 - accuracy: 0.8569 - val_loss: 0.4143 - val_accuracy: 0.8638\n",
            "Epoch 185/200\n",
            "781/781 - 33s - loss: 0.4147 - accuracy: 0.8587 - val_loss: 0.3856 - val_accuracy: 0.8724\n",
            "Epoch 186/200\n",
            "781/781 - 33s - loss: 0.4095 - accuracy: 0.8584 - val_loss: 0.3867 - val_accuracy: 0.8715\n",
            "Epoch 187/200\n",
            "781/781 - 32s - loss: 0.4120 - accuracy: 0.8602 - val_loss: 0.4070 - val_accuracy: 0.8664\n",
            "Epoch 188/200\n",
            "781/781 - 32s - loss: 0.4156 - accuracy: 0.8578 - val_loss: 0.3974 - val_accuracy: 0.8699\n",
            "Epoch 189/200\n",
            "781/781 - 32s - loss: 0.4020 - accuracy: 0.8615 - val_loss: 0.4093 - val_accuracy: 0.8657\n",
            "Epoch 190/200\n",
            "781/781 - 32s - loss: 0.4073 - accuracy: 0.8608 - val_loss: 0.4337 - val_accuracy: 0.8558\n",
            "Epoch 191/200\n",
            "781/781 - 32s - loss: 0.4065 - accuracy: 0.8612 - val_loss: 0.4169 - val_accuracy: 0.8642\n",
            "Epoch 192/200\n",
            "781/781 - 32s - loss: 0.4096 - accuracy: 0.8590 - val_loss: 0.4145 - val_accuracy: 0.8648\n",
            "Epoch 193/200\n",
            "781/781 - 32s - loss: 0.4128 - accuracy: 0.8597 - val_loss: 0.4206 - val_accuracy: 0.8613\n",
            "Epoch 194/200\n",
            "781/781 - 32s - loss: 0.4144 - accuracy: 0.8565 - val_loss: 0.4088 - val_accuracy: 0.8668\n",
            "Epoch 195/200\n",
            "781/781 - 32s - loss: 0.4015 - accuracy: 0.8622 - val_loss: 0.3834 - val_accuracy: 0.8724\n",
            "Epoch 196/200\n",
            "781/781 - 32s - loss: 0.4034 - accuracy: 0.8625 - val_loss: 0.4077 - val_accuracy: 0.8672\n",
            "Epoch 197/200\n",
            "781/781 - 32s - loss: 0.4044 - accuracy: 0.8628 - val_loss: 0.3972 - val_accuracy: 0.8696\n",
            "Epoch 198/200\n",
            "781/781 - 32s - loss: 0.4097 - accuracy: 0.8600 - val_loss: 0.4294 - val_accuracy: 0.8620\n",
            "Epoch 199/200\n",
            "781/781 - 32s - loss: 0.4014 - accuracy: 0.8637 - val_loss: 0.3934 - val_accuracy: 0.8687\n",
            "Epoch 200/200\n",
            "781/781 - 32s - loss: 0.4017 - accuracy: 0.8617 - val_loss: 0.3906 - val_accuracy: 0.8702\n",
            "Validation Accuracy > 87.020\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHHljGc8mOq0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}